import json
from langchain_core.documents import Document
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings


# ---------------- Paths ----------------
JSON_PATH = "st4data.json"
CHROMA_DIR = "chroma_store"

print("ğŸ”¹ Starting insurance quote ingestion pipeline...\n")

# ---------------- Load JSON ----------------
print(f"ğŸ“‚ Loading data from: {JSON_PATH}")
with open(JSON_PATH, "r", encoding="utf-8") as f:
    data = json.load(f)

print(f"âœ… Loaded raw JSON with {len(data)} entries\n")

# ---------------- Convert to LangChain Documents ----------------
print("ğŸ§© Converting JSON entries into LangChain Documents...")
documents = []

for idx, item in enumerate(data, start=1):
    doc = Document(
        page_content=item["content"],   # text for embeddings
        metadata=item["metadata"]        # structured metadata
    )
    documents.append(doc)

    # Lightweight progress update
    print(f"   âœ” Prepared document {idx}/{len(data)}")

print("\nâœ… All documents prepared successfully\n")

# ---------------- MiniLM Embeddings ----------------
print("ğŸ§  Initializing MiniLM-L6-v2 embedding model (local, free)...")
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)
print("âœ… Embedding model loaded\n")

# ---------------- Create Chroma Vector DB ----------------
print("ğŸ“¦ Creating Chroma vector database...")
vector_db = Chroma.from_documents(
    documents=documents,
    embedding=embeddings,
    persist_directory=CHROMA_DIR
)

print("ğŸ’¾ Persisting vector database to disk...")
vector_db.persist()

print("\nğŸ‰ SUCCESS!")
print("âœ… Quotes successfully stored in ChromaDB using MiniLM-L6-v2")
print(f"ğŸ“ Vector store location: {CHROMA_DIR}")
